# Story 3.1: Generate TTS and return `tts_audio_url` in `POST /turn`

Status: done

<!-- Note: Validation is optional. Run validate-create-story for quality check before dev-story. -->

## Story

As a user,
I want the interviewer response spoken aloud,
So that the interview feels conversational.

## Acceptance Criteria

1. **Given** a successful `POST /turn` response
   **When** TTS is generated for the assistant response
   **Then** the backend caches the audio in-memory keyed by `request_id`
   **And** returns a `tts_audio_url` that the client can fetch

2. **Given** the TTS provider (Deepgram Aura) is available
   **When** `assistant_text` is generated by the LLM
   **Then** Deepgram's `POST /v1/speak` endpoint is called with the text
   **And** raw audio bytes (MP3) are returned and cached

3. **Given** the TTS audio is cached
   **When** the turn response JSON is constructed
   **Then** `tts_audio_url` is a valid path matching the format `/tts/{request_id}`
   **And** `timings` includes `tts_ms` for the TTS stage duration

4. **Given** a TTS provider failure (timeout, rate limit, 5xx)
   **When** the error is retryable
   **Then** the turn response still includes `transcript` and `assistant_text`
   **And** `tts_audio_url` is `null` (graceful degradation)
   **And** the error is logged with `request_id`

5. **Given** a TTS provider failure
   **When** the error is non-retryable (auth error, bad request)
   **Then** the error is raised as a `TurnProcessingError` with stage `tts`
   **And** includes `code`, `message_safe`, `retryable`, and `request_id`

6. **Given** the `POST /turn` request is a transcript retry (no audio, transcript provided)
   **When** the LLM generates a new assistant_text
   **Then** TTS is still generated for the new response text

7. **Given** the TTS cache stores audio
   **When** entries are stored
   **Then** each entry has a TTL (default 5 minutes) after which it is evicted to prevent memory leaks

## Tasks / Subtasks

### Task 1: Create `DeepgramTTSProvider` (AC: #2, #4, #5)

- [x] 1.1 Create `services/api/src/providers/tts_deepgram.py`:
  - Class `DeepgramTTSProvider` following the pattern of `DeepgramSTTProvider`
  - Constructor accepts `api_key: str`, `timeout_seconds: int = 30`, `model: str = "aura-2-thalia-en"`
  - Method `async synthesize(text: str) -> bytes` — calls Deepgram `POST /v1/speak` and returns raw audio bytes
  - Error hierarchy: `TTSError` (base), `TTSTimeoutError`, `TTSProviderError`, `TTSRateLimitError`, `TTSAuthError`, `TTSBadRequestError`
  - All errors carry `stage="tts"`, `code`, and `retryable` fields (same pattern as `STTError`)
- [x] 1.2 Update `services/api/src/providers/__init__.py` to export the new TTS classes
- [x] 1.3 Verify no dependency conflicts — the existing `httpx` package is sufficient (no new pip deps needed for REST calls to Deepgram)

### Task 2: Create `TTSCache` service (AC: #1, #7)

- [x] 2.1 Create `services/api/src/services/tts_cache.py`:
  - Class `TTSCache` — in-memory cache for TTS audio bytes keyed by `request_id`
  - Method `store(request_id: str, audio_bytes: bytes)` — stores audio with a timestamp
  - Method `get(request_id: str) -> bytes | None` — returns audio bytes or `None` if expired/missing
  - Method `cleanup()` — evicts entries older than the configured TTL
  - TTL default: 300 seconds (5 minutes), configurable via constructor
  - Uses a simple `dict[str, tuple[bytes, float]]` (bytes + timestamp)
- [x] 2.2 Create a module-level singleton or FastAPI dependency for `TTSCache`
- [x] 2.3 Update `services/api/src/services/__init__.py` to export `TTSCache`

### Task 3: Add TTS settings to configuration (AC: #2)

- [x] 3.1 Add to `services/api/src/settings/config.py` `Settings` class:
  - `tts_timeout_seconds: int = 30`
  - `tts_model: str = "aura-2-thalia-en"` (Deepgram Aura-2 default voice)
  - `tts_cache_ttl_seconds: int = 300`
- [x] 3.2 Update `services/api/.env.example` with new TTS config variables (optional, since Deepgram key is shared with STT)

### Task 4: Integrate TTS into orchestrator pipeline (AC: #1, #2, #3, #4, #5, #6)

- [x] 4.1 Modify `services/api/src/services/orchestrator.py`:
  - Import `DeepgramTTSProvider`, `TTSError`, and `TTSCache`
  - Add `get_tts_provider()` factory function (same pattern as `get_stt_provider()`)
  - In `process_turn()`, after LLM completes:
    - Call `tts_provider.synthesize(assistant_text)`
    - If successful: store audio in `TTSCache` keyed by `request_id`, set `tts_audio_url = f"/tts/{request_id}"`
    - If TTS fails with a retryable error: log warning, set `tts_audio_url = None` (graceful degradation)
    - If TTS fails with a non-retryable error: raise `TurnProcessingError` with stage `tts`
  - Add `tts_ms` to the `timings` dict
  - Update the docstring from "STT → LLM → (TTS deferred)" to "STT → LLM → TTS"
- [x] 4.2 Update `TurnResult` docstring to remove "placeholders for future TTS integration (Story 3.1)" comment
- [x] 4.3 Update error taxonomy docstring in orchestrator to include TTS stage error codes:
  - `tts_timeout`, `tts_provider_error`, `tts_rate_limit`, `tts_auth_error`, `tts_bad_request`

### Task 5: Pass `TTSCache` through turn route (AC: #1)

- [x] 5.1 Modify `services/api/src/api/routes/turn.py`:
  - Add `TTSCache` as a FastAPI dependency
  - Pass the cache instance to `process_turn()` (or make it accessible within the orchestrator)
- [x] 5.2 Ensure `tts_audio_url` from `TurnResult` is passed through to `TurnResponseData` in the response

### Task 6: Update `TurnResponseData` model (AC: #3)

- [x] 6.1 Update `services/api/src/api/models/turn_models.py`:
  - Change `tts_audio_url` description from "null until Story 3.1" to "URL to fetch TTS audio of assistant_text"
  - Update examples to show a valid relative URL: `"/tts/550e8400-e29b-41d4-a716-446655440000"`

### Task 7: Write unit tests (AC: #1–#7)

- [x] 7.1 Create `services/api/tests/unit/test_tts_deepgram.py`:
  - Test: successful synthesis returns audio bytes
  - Test: timeout raises `TTSTimeoutError`
  - Test: 401/403 raises `TTSAuthError`
  - Test: 429 raises `TTSRateLimitError`
  - Test: 4xx raises `TTSBadRequestError`
  - Test: 5xx raises `TTSProviderError`
  - Test: correct headers and payload sent to Deepgram
- [x] 7.2 Create `services/api/tests/unit/test_tts_cache.py`:
  - Test: store and retrieve audio bytes
  - Test: get returns None for missing key
  - Test: get returns None for expired entry
  - Test: cleanup removes expired entries
  - Test: cleanup preserves non-expired entries
- [x] 7.3 Update `services/api/tests/unit/test_turn_route.py`:
  - Test: successful turn includes `tts_audio_url`
  - Test: TTS failure with retryable error → response has `tts_audio_url: null`
  - Test: TTS failure with non-retryable error → raises TurnProcessingError
  - Test: `tts_ms` is present in timings
- [x] 7.4 Verify all existing tests still pass (regression check)

## Dev Notes

### Existing Infrastructure (ALREADY BUILT — leverage, don't rebuild)

**`DeepgramSTTProvider`** (`services/api/src/providers/stt_deepgram.py`):

- Already has the complete `httpx`-based pattern for calling Deepgram APIs
- Error hierarchy: `STTError` (base) → timeout/auth/rate-limit/provider/bad-request subclasses
- All errors carry `stage`, `code`, `retryable` fields
- **FOLLOW THIS EXACT PATTERN for TTS** — same auth header format (`Token {api_key}`), same error handling structure

**`orchestrator.py`** (`services/api/src/services/orchestrator.py`):

- `TurnResult` already has `tts_audio_url: str | None = None` placeholder — this field just needs to be populated
- `process_turn()` already has the STT → LLM pipeline with proper timing
- Already has factory functions `get_stt_provider()` and `get_llm_provider()` — add `get_tts_provider()` following the same pattern
- Already handles `STTError` and `LLMError` wrapping → add `TTSError` wrapping

**`TurnResponseData`** (`services/api/src/api/models/turn_models.py`):

- Already has `tts_audio_url: str | None = Field(default=None, ...)` — no model changes needed beyond updating the description
- Already has `timings: dict[str, float]` — just needs `tts_ms` added by the orchestrator

**`Settings`** (`services/api/src/settings/config.py`):

- Already has `deepgram_api_key` — TTS uses the SAME Deepgram API key
- Already has `stt_timeout_seconds` as a pattern → add `tts_timeout_seconds`

**`requirements.txt`** (`services/api/requirements.txt`):

- Already has `httpx==0.28.1` for HTTP calls — NO new dependency needed for Deepgram REST TTS
- Deepgram TTS is a simple REST API: `POST https://api.deepgram.com/v1/speak`

### What Needs to Be Built

This story is about **generating TTS audio and caching it for client fetch**:

1. **`DeepgramTTSProvider`** — New provider calling Deepgram Aura-2 `POST /v1/speak` REST API
2. **`TTSCache`** — New in-memory cache for audio bytes keyed by `request_id` with TTL eviction
3. **Orchestrator integration** — Extend the pipeline: STT → LLM → **TTS** (with graceful degradation)
4. **Turn route wiring** — Pass `TTSCache` dependency and populate `tts_audio_url` in the response
5. **Tests** — Unit tests for provider, cache, and integration with orchestrator

### Architecture-Mandated Patterns

From architecture.md:

- **Provider location:** `services/api/src/providers/tts_deepgram.py` — MUST go here
- **Service location:** `services/api/src/services/tts_cache.py` — MUST go here
- **TTS endpoint architecture:** Two-step TTS pattern:
  - `POST /turn` returns JSON with `tts_audio_url` (relative URL like `/tts/{request_id}`)
  - `GET /tts/{request_id}` serves audio bytes from in-memory cache (Story 3.2)
- **API response format:** `{ "data": <payload>, "error": null, "request_id": "<id>" }` — always wrapped
- **JSON fields:** `snake_case` — `tts_audio_url`, `tts_ms`, not `ttsAudioUrl`
- **Error taxonomy:** Stage-aware errors with `{ stage, code, message_safe, retryable }`; TTS stage is `"tts"`
- **Request ID:** `X-Request-ID` echoed in both headers and JSON body; used as TTS cache key
- **Backend project organization:** routes in `api/routes/`, models in `api/models/`, services in `services/`, providers in `providers/`
- **Deepgram Aura TTS:** Architecture specifies Deepgram Aura as the TTS provider with Deepgram SDK `5.3.1` listed but **we use direct REST API via httpx** (consistent with STT implementation)

### Deepgram TTS API Details (Latest — Feb 2026)

**Endpoint:** `POST https://api.deepgram.com/v1/speak`

**Headers:**

- `Authorization: Token {deepgram_api_key}` (same key as STT)
- `Content-Type: application/json`

**Request Body:**

```json
{ "text": "Hello, how can I help you today?" }
```

**Query Parameters:**

- `model` — Voice model (default: `aura-asteria-en`, our choice: `aura-2-thalia-en`)
- `encoding` — Output format (`mp3`, `linear16`, `alaw`, `mulaw`, `flac`, `aac`)
- `sample_rate` — Sample rate (default varies by encoding)

**Response:** Raw audio bytes with `Content-Type: audio/mpeg` (for MP3)

**Key Facts:**

- Uses the SAME Deepgram API key as STT — no new credentials needed
- Aura-2 offers TTFB under 200ms (ultra-low latency)
- Default MP3 output — compatible with `just_audio` on the mobile app
- ~$0.03 per 1,000 characters
- Rate limits apply — handle 429 responses

### UX Specifications (from ux-design-specification.md)

- **Speaking state:** UI transitions to "Speaking" when TTS begins playback
- **Voice Pipeline Stepper:** Uploading → Transcribing → Thinking → **Speaking** (4 stages visible)
- **Voice-first, not voice-only:** `assistant_text` MUST still be shown as readable text alongside audio
- **No overlap:** Never play TTS while recording; single playback queue
- **Graceful degradation:** If TTS fails, the text response is still shown — the interview can continue without audio

### Previous Story Learnings (from Story 2.8)

- **80-char line length:** Python follows PEP 8 (79-char limit), be mindful in provider code
- **Error handling pattern:** All provider exceptions inherit from a base `Error` class with `stage`, `code`, `retryable` fields
- **Logging:** Use Python's `logging` module, structured with `request_id`
- **Test patterns:** Use `pytest-asyncio` for async tests, `httpx` for HTTP mocking
- **Feature branches:** Use the pattern `feature/story-3-1-short-description`
- **Conventional commits:** `feat:`, `fix:`, `test:` prefixes

### Git Intelligence (Recent Commits)

```
403addf docs: Add sprint status tracking and Epic 2 retrospective documents.
3368853 Merge pull request #19 from AvishkaGihan/feature/2-8-handle-interruptions
d1d33cb feat(interview): pass InterviewCubit to DiagnosticsPage during navigation
621ad02 feat(mobile/interview): handle audio focus interruptions during recording
ee848b3 Merge pull request #18 from AvishkaGihan/feature/story-2-7
979ee06 feat: implement story 2.7 - latency timings captured and surfaced basic
```

Key observations:

- Epic 2 is fully complete (all stories done, retrospective done)
- Feature branch naming: `feature/story-X-Y-short-description`
- Commit convention: `feat:`, `fix:`, `test:` prefixes used consistently
- Epic 3 starts fresh — no existing TTS code in the codebase

### Critical Naming Conventions

- **File names:** `snake_case` — `tts_deepgram.py`, `tts_cache.py`
- **Class names:** `PascalCase` — `DeepgramTTSProvider`, `TTSCache`, `TTSError`
- **Python fields:** `snake_case` — `tts_audio_url`, `tts_ms`
- **Provider directory:** `services/api/src/providers/` for `tts_deepgram.py`
- **Service directory:** `services/api/src/services/` for `tts_cache.py`
- **Test directory:** `services/api/tests/unit/` for provider and cache tests
- **Error codes:** `tts_timeout`, `tts_provider_error`, `tts_rate_limit`, `tts_auth_error`, `tts_bad_request`

### File Inventory

**Files to create:**

- `services/api/src/providers/tts_deepgram.py` — Deepgram Aura TTS provider
- `services/api/src/services/tts_cache.py` — In-memory TTS audio cache with TTL
- `services/api/tests/unit/test_tts_deepgram.py` — TTS provider unit tests
- `services/api/tests/unit/test_tts_cache.py` — TTS cache unit tests

**Files to modify:**

- `services/api/src/services/orchestrator.py` — Extend pipeline: STT → LLM → TTS
- `services/api/src/services/__init__.py` — Export TTSCache
- `services/api/src/providers/__init__.py` — Export TTS classes
- `services/api/src/settings/config.py` — Add TTS settings
- `services/api/src/api/routes/turn.py` — Wire TTSCache dependency
- `services/api/src/api/models/turn_models.py` — Update tts_audio_url description
- `services/api/tests/unit/test_turn_route.py` — Add TTS integration tests

**Files to validate (likely NO changes):**

- `services/api/requirements.txt` — httpx already present; no new deps
- `services/api/src/providers/stt_deepgram.py` — Reference pattern only, no changes
- `services/api/src/providers/llm_groq.py` — Reference pattern only, no changes

### Gotchas / Anti-Patterns to Avoid

1. **DO NOT use Deepgram SDK** — The existing STT provider uses raw `httpx` calls, not the Deepgram Python SDK. Keep TTS consistent with this approach. The architecture mentions SDK `5.3.1` but the actual implementation uses direct HTTP.

2. **DO NOT persist TTS audio to disk** — Architecture mandates in-memory cache only. Audio bytes are transient; the TTSCache handles storage and TTL.

3. **DO NOT block the turn response on TTS failures** — For retryable TTS errors (timeout, rate limit, 5xx), the turn response should still succeed with `tts_audio_url: null`. The client can display the text response without audio. Only non-retryable errors (auth, bad request) should propagate.

4. **DO NOT create the `GET /tts/{request_id}` endpoint yet** — That is Story 3.2. This story only generates TTS, caches it, and returns the URL in the response.

5. **DO NOT add new pip dependencies** — `httpx` is already in `requirements.txt` and is sufficient for Deepgram REST API calls. Do not add `deepgram-sdk` or any other package.

6. **DO NOT store the full backend URL in `tts_audio_url`** — Return a relative path like `/tts/{request_id}`. The mobile client will prepend the base URL.

7. **DO NOT hardcode the Deepgram API key** — Use `settings.deepgram_api_key` from the Settings class (same key used for STT).

8. **DO NOT forget to add `tts_ms` to timings** — The timing dict must include TTS stage timing for the diagnostics surface.

9. **DO NOT use the Deepgram SDK's built-in error types** — Create custom `TTSError` hierarchy following the exact same pattern as `STTError` (base class with stage/code/retryable fields, plus specific subclasses).

10. **DO NOT forget TTL cleanup in TTSCache** — Without cleanup, the cache will grow unbounded. Implement lazy cleanup on `get()` or periodic cleanup.

### Project Structure Notes

- `tts_deepgram.py` goes in `services/api/src/providers/` — consistent with `stt_deepgram.py` and `llm_groq.py`
- `tts_cache.py` goes in `services/api/src/services/` — consistent with `session_store.py` (another in-memory store)
- Tests mirror source structure: `services/api/tests/unit/`
- No new feature directories needed — this extends the existing backend services
- TTS model choice (`aura-2-thalia-en`) is configurable via settings for easy swapping

### References

- [Source: _bmad-output/planning-artifacts/epics.md#Story 3.1] — FR23, FR24 acceptance criteria
- [Source: _bmad-output/planning-artifacts/architecture.md#API & Communication Patterns] — Two-step TTS contract, `GET /tts/{request_id}`
- [Source: _bmad-output/planning-artifacts/architecture.md#Core Architectural Decisions] — Deepgram Aura TTS, in-memory cache
- [Source: _bmad-output/planning-artifacts/architecture.md#Project Structure & Boundaries] — `providers/tts_deepgram.py`, `services/tts_cache.py`
- [Source: _bmad-output/planning-artifacts/ux-design-specification.md#Voice Pipeline Stepper] — Speaking stage UX
- [Source: _bmad-output/planning-artifacts/ux-design-specification.md#Component Strategy] — Audio controls, playback queue
- [Source: _bmad-output/implementation-artifacts/2-8-handle-interruptions-during-recording-android.md#Dev Notes] — Previous story patterns
- [Source: Deepgram TTS REST API] — `POST /v1/speak`, model `aura-2-thalia-en`, MP3 output

### Change Log

| Date       | Change                                                                              | Author                 |
| ---------- | ----------------------------------------------------------------------------------- | ---------------------- |
| 2026-02-16 | Story 3.1 created — comprehensive context for TTS generation in POST /turn pipeline | Antigravity (SM Agent) |

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (Dev Agent - Amelia)

### Debug Log References

N/A

### Completion Notes List

- Implemented full TTS pipeline: DeepgramTTSProvider → TTSCache → orchestrator integration
- All 7 tasks completed successfully with comprehensive test coverage
- Test suite: 83 tests passing (16 orchestrator, 9 turn route, 7 TTS provider, 8 TTS cache, plus existing tests)
- Graceful degradation implemented: retryable TTS errors result in `tts_audio_url: null` without failing the turn
- Non-retryable TTS errors (auth, bad request) properly propagate as TurnProcessingError with stage="tts"
- TTS timing (`tts_ms`) captured and included in response timings dict
- TTL-based cache cleanup implemented (lazy on get, proactive via cleanup() method)
- Thread-safe cache implementation with threading.Lock
- Used existing httpx client pattern from DeepgramSTTProvider (no new dependencies)
- API signature change: `process_turn()` now requires `tts_cache` parameter (breaking change - all tests updated)
- **Code Review Fixes (AI):**
  - Implemented missing TTS error handling tests in `test_turn_route.py`
  - Patched `test_orchestrator.py` to mock `get_tts_provider` in all existing tests to fix `httpx.LocalProtocolError`
  - Added specific unit tests for retryable/non-retryable TTS errors in `test_orchestrator.py`

### File List

**Created:**

- `services/api/src/providers/tts_deepgram.py` — Deepgram Aura-2 TTS provider
- `services/api/src/services/tts_cache.py` — In-memory TTS audio cache with TTL
- `services/api/tests/unit/test_tts_deepgram.py` — TTS provider unit tests (7 tests)
- `services/api/tests/unit/test_tts_cache.py` — TTS cache unit tests (8 tests)

**Modified:**

- `services/api/src/providers/__init__.py` — Added TTS exports
- `services/api/src/services/__init__.py` — Added TTSCache export
- `services/api/src/settings/config.py` — Added tts_timeout_seconds, tts_model, tts_cache_ttl_seconds
- `services/api/.env.example` — Added TTS configuration comments
- `services/api/src/services/orchestrator.py` — Integrated TTS into process_turn() pipeline
- `services/api/src/api/dependencies/shared_services.py` — Added get_tts_cache() singleton
- `services/api/src/api/routes/turn.py` — Added tts_cache dependency
- `services/api/src/api/models/turn_models.py` — Updated tts_audio_url description
- `services/api/tests/unit/test_orchestrator.py` — Added mock_tts_cache fixture, updated all 16 tests
- `services/api/tests/unit/test_turn_route.py` — Updated all 6 mock functions, added 3 TTS integration tests
- `_bmad-output/implementation-artifacts/sprint-status.yaml` — Updated story status to "review"
